[<](../README.md)

# Identify the core AWS services

## Describe the categories of services on AWS (compute, storage, network, database)

## Identify AWS compute services

### **Recognize there are different compute families**

### **Recognize the different services that provide compute** 

for example, AWS Lambda compared to Amazon Elastic Container Service (Amazon ECS), or Amazon EC2, etc.)



**AWS Lambda** is a manage AWS service that allows a customer to craft custom functions to carry out any task written in a variety of programming languages. Lambda is available as a hosted service at each edge location.

### **Recognize that elasticity is achieved through Auto Scaling**

Real-time monitoring of a hosted cloud application allows AWS to react almost instantaneously before the application's performance is close to degrading. 

**EC2 Auto Scaling** > Additional computer resources are automatically ordered and delivered to the application server's cluster maintaining the server performance.

*Rapid elasticity based on demand is only possible with real-time monitoring driving automated scale*

### **Identify the purpose of load balancers**


## Identify different AWS storage services
### **Describe Amazon S3**
### **Describe Amazon Elastic Block Store (Amazon EBS)**
### **Describe Amazon S3 Glacier**
### **DescriCbe AWS Snowball**
### **Describe Amazon Elastic File System (Amazon EFS)**
### **Describe AWS Storage Gateway**



## Identify AWS networking services

### **Identify VPC**

Networking at AWS is called the **virtual private cloud (VPC)**. The official name of a VPC is **EC2-VPC**. The **EC2 (Elastic Cloud Compute)** designation indicates that EC2 instances are usually hosted within a VPC. 

Each VPC is a logically isolated "data center" where computer instances and various AWS services reside.

**OBS:** Amazon job when a customer order a VPC:
- Amazon must make sure that my VPC is a private isolated software data center linked to my AWS account. 
- Amazon must ensure the continued separation of my VPC from all other customers. 
- Amazon also guarantees that network traffic is routed and protected based on my architecture design and needs.
- Im sum, **AWS's job is to provision, host, and secure the VPC**.

AWS services can be **hosted within**, or **associated to** a VPC. This means that some of the services will have relationships with the services and components hosted *inside* a VPC, but the services themselves are not actually *installed in* the VPC.

Examples of Hosted VPC Services: 
- EC2 instances
- Elastic Beanstalk
- Amazon Redshift
- ElastiCache
- Amazon EMR
- Amazon RDS
- Amazon Workspaces

Examples of Associated Services
- Trusted Advisor
- AWS Config
- VPN connections
- Auto scaling
- Elastic load balancing
- S3
- DynamoDB


VPCs run on top of the physical AWS network infrastructure that a customer don't have access. Within each VPC, the networking exposed to each customer is designed and managed at the subnet level.

There are three ways for creating a VPC:
- Create VPC Dashboard
- Launch VPC Wizard
- Amazon Command-Line Interface (CLI)

There is a default "soft limit" to how many VPCs a customer can initially create: 5 VPCs. A customer can request additional VPCs resources up to a defined "hard limit": *current number of VPCs in the region* * *number of security groups per VPC* (this cannot exceed 1000).

VPCs are originally a blank slate except for the primary **IPv4 CIDR block** and the local **main routing table**. IPv6 CIDR blocks can also be associated with a VPC, but only after an  initial IPv4 CIDR block has been created. 

The primary IPv4 CIDR block that a customer choose for the VPC will determine the number and size of IPv4 addresses that can be assigned to the subnets created within the VPC. 

The initial CIDR block added when creating a VPC can't be changed; however, a customer has the option of adding additional secondary CIDR blocks to an existing VPC.

Up to four secondary IPv4 CIDR blocks can be associated with an existing VPC. The additional secondary CIDR block cannot be larger than the primary CIDR block.

Vantage of being able to add additional secondary CIDR blocks to an existing VPC: the ability to add future expansion when necessary. 

Config of default VPC:
- IPv4 CIDR block of 172.30.0.0/16, which provides up to 65531 private IP v4 addresses
- Internet gateway with a route table entry
- Default security group
- Default network ACL

#### *Subnets*

After initial VPC creation, the next step is to create subnets within the VPC, per AZ(s), depending on required network design. Each subnet that a customer create resides within its assigned AZ.

**OBS:** AZs don't show up automatically in each VPC; they are added during subnet creation when selecting each subnet's location.

Subnets are defined by their connectivity options
- **public subnet**: subnet traffic is routed to the internet through an Internet gateway
- **private subnet**: the subnet has no gateway or endpoint to direct traffic to. 

Summary of subnets:
- Subnets are contained within an AZ
- Subnets host compute instances
- Public subnets allow you access to the Internet
- Public subnets are for infrastructure
- Private subnets are private with no Internet access
- Private subnets are where instances live privately
- VPN-only subnets have access to A VPN connection

**OBS:** At AWS, a NAT gateway service can be ordered and linked to a public subnet to allow EC2 instances in a private subnet to connect to the internet and receive required operating system and application updates.

#### *Route tables*

A subnet **route table** is a defined collection of rules that dictate where egress subnet network traffic can flow to.

The main route table provides local routing services throughout the VPC across all defined AZs.

Each route table has an entry containing the VPC's initial CIDR designations, and this entry cannot be changed.

It is considered a best practice to create **custom route tables** for each tier in your network design. Creation of custom route tables allows you granular control of traffic flow within each subnet.


#### *Private vs. Public vs. Elastic IPv4 Addresses*

**Private IP addresses** communicate across the private network at AWS. When a client launches a new EC2 instance, by default, Amazon assigns a private IP address. If you choose to manually assign a primary private IP address, the IP address chosen must be available in the subnet’s IP address range

**OBS:** Once a primary private IP address is assigned, the EC2 instance retains the address for the lifetime of the instance. Additional, secondary private IP addresses can also be assigned to the network interfaces of an EC2 instance, and these addresses can be  unassigned and moved between other EC2 instances that reside on the same subnet at any time

**Public IP addresses** are an option for the customer, are not available by default, and are not permanently assigned to an EC2 instance. 

**OBS:** Public IP addresses from AWS’s own pool are managed and controlled by AWS. To make sure that AWS doesn’t run out of addresses, the AWS-assigned public IP address is detached when an EC2 instance is turned off.

A **public elastic IP address (EIP)** is a static public IP address that after creation is assigned to your account at AWS.

Therefore, at AWS, there are two public pools of IP addresses to consider: Dynamically assigned public IP addresses that are returned to the common public pool of AWS addresses, or elastic IP addresses, which are assigned as desired after ordering and assigned to a customer’s account.


#### *Peering VPCs*

When a company has multiple VPCs in many AWS accounts, we can create networking connections between VPCs through a process called **peering**, enabling you to route traffic between VPCs that have been peered together.

Peering can be carried out between your own account VPCs or between a VPC assigned to another AWS account. Peered VPCs can also reside in completely different regions


### **Identify security groups**

Security groups operate at the EC2 intance level and protect your server's incoming network connections by placing a software firewall around each attached network interface.

Each security group **is a collection of inbound and outbound rules that designate the port and protocols allowed into and of each network interface**. It works as a reusable security template stored in your AWS account. Once a security group has been created, it can be assigned multiple times within the VPC where it was created, protecting one or many EC2 instances.

Security groups summary:
- Security groups are associated with a particular VPC.
- Each network interface assigned to an instanced hosted withing a VPC can be associated with up to five security groups.
- Security groups define only allow rules
- Security groups don’t deny traffic explicitly; instead, they deny traffic implicitly by only stating what is allowed
- Security group rules allow you to direct traffic outbound from one security group and inbound to another security group within the same VPC
- Security groups are defined as stateful: if requests are allowed in, response traffic is allowed out regardless of defined outbound rules
- For each rule you define: protocal, port, port range, and source of inbound rules or destination outbound rules for the traffic
- Protocols allowed: TCP, UDP, or ICMP

**OBS:** If you don’t pay attention and don’t specify a custom security group when an EC2 instance is created, at launch, the default security group is associated automatically.

We can create custom security groups by establishing:
- **Inbound rules:** Define the source of the traffic—that is, where it is coming from, and what the destination port or port range is.
- **Outbound rules:** Define the destination of the traffic—that is, where it is going to, and the destination port, or port range

#### *Gateway VPC Endpoints*
VPC endpoints are defined as a gateway, or interface endpoint.

VPC endpoints allow you to connect VPC subnets to AWS services without  requiring an Internet gateway, VPN connection, or a peering connection be set up first.

Endpoints are another AWS service designed as a horizontally scaled redundant, highly available service.

VPC endpoints are controlled by an endpoint policy, which is also a  IAM (identity and access management) resource. IAM policies define the exact permissions allowed or denied.


### **Identify the purpose of Amazon Route 53**

As a customer access an application hosted at AWS, an application query will be carried out. This is accomplished using DNS (Domain Name System).

Route 53 is Amazon's hosted DNS service and it's highly scalable and highly available. Its primary job is to route end users to hosted applications at AWS.

Route 53 has a public side pointed to the public edge locations that accepts incoming customer requests and then resolves each query to the requested AWS resource located on Route 53's private side.

Route 53 supports a variety of routing protocols, including: 
- round robin (WRR): WRR allows you to assign weights to resource record sets
- latency-based routing (LBR): LBR is utilized when you are balancing application performance across multiple regions
- Geo DNS:  allows you to balance user requests to specific endpoints based on the geographical location the user request came from.

Route 53 also offers health checking and traffic-steering services for routing selected traffic to a healthy endpoint in multiple AWS regions

Route 53 health checks constantly verifies that your applications are reachable and available. Health checks are supported for HTTPS, HTTP, and TCP.

Health checks can also be carried out using the built-in monitoring service CloudWatch using many defined metrics.


### **Identify VPN, AWS Direct Connect**

A **VPN connection** is a site-to-site tunnel connection between your VPC and your corporate network. 

The purpose of **AWS Direct Connect** is to connect your internal corporate network to a Direct connect (DC) location over a private high-speed fiber connection with no Internet connection.